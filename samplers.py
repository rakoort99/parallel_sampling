import numpy as np
import pandas as pd
import multiprocessing
import random
import time
import os


def gibbs_update(idx: list, states, full_conditionals):
    return full_conditionals(states, idx)


def seq_gibbs(init: list, full_conditionals, N=1000):
    """Sequential Gibbs Sampling

    Args:
        init (list): List denoting initialization at each node in the factor graph
        full_conditionals (func): Function which return samples from full conditional distribution. Inputs must be (list_of_states, idx_to_update)
        N (int, optional): Number of samples to generate. Defaults to 1000.

    Returns:
        np.array: array of generated samples.
    """

    samples = [init]
    idx_max = len(init)
    for i in range(N):
        idx = np.random.randint(0, idx_max)
        newval = gibbs_update(idx, samples[-1], full_conditionals)
        nextstate = samples[-1].copy()
        nextstate[idx] = newval
        samples.append(nextstate)
    return np.array(samples)


def hog_gibbs(init: list, full_conditionals, N: int = 10**3, n_workers: int = 8):
    """Hogwild Gibbs Sampler

    Args:
        init (list): List denoting initialization at each node in the factor graph
        full_conditionals (func): Function which return samples from full conditional distribution. Inputs must be (list_of_states, idx_to_update)
        N (int, optional): Number of "time units" to generate samples in. Defaults to 1000.
        num_processes (int, optional): Number of workers to utilize. Defaults to 8.

    Returns:
        np.narray: array of generated samples.
    """

    # appends gibbs updates to global list of samples until
    def append_to_list(shared_list, stop_event):
        np.random.seed((os.getpid() * int(time.time())) % 123456789)
        idx_max = len(shared_list[0])
        while not stop_event.is_set():
            idx = np.random.randint(0, idx_max)
            newval = gibbs_update(idx, shared_list[-1], full_conditionals)
            nextstate = shared_list[-1].copy()
            nextstate[idx] = newval
            shared_list.append(nextstate)

    global_list = multiprocessing.Manager().list([init])

    # Event to signal processes to stop
    stop_event = multiprocessing.Event()

    # Create a process for each appending task
    processes = []
    for _ in range(n_workers):
        process = multiprocessing.Process(
            target=append_to_list, args=(global_list, stop_event)
        )
        process.start()
        processes.append(process)

    # Let the processes run
    while len(global_list) < n_workers * N:
        pass

    # Set the stop event to signal the processes to stop appending
    stop_event.set()

    # Wait for all processes to finish
    for process in processes:
        process.join()
    return np.array(global_list)


def exact_async(
    init: list,
    full_conditionals,
    transition_probs,
    joint_pdf,
    N: int = 1000,
    n_workers: int = 8,
    discrete: int = False,
):
    """Exact asynchronous Gibbs sampler

    Args:
        init (list): list of initial states for each node in factor graph
        full_conditionals (func): Function to draw samples from full conditional distributions. Takes as inputs (current_state, site_to_update)
        transition_probs (func): Function to evaluate one-step transition probabilities. Takes as inputs (update, index_of_update, previous_state)
        joint_pdf (func): Function to evaluate (un-normalized) joint PDF. Takes as inputs (state)
        N (int, optional): Number of samples to draw. Defaults to 1000.
        n_workers (int, optional): Number of workers to use. Defaults to 8.
        discrete (int, optional): Whether or not the distribution to draw from is discrete. Defaults to False.

    Returns:
        dict: dictionary of arrays of states generated by each worker. keys correspond to each worker's index.
    """

    # create dataframe, dict for necessary shared information
    df = pd.DataFrame(columns=["t", "worker"])
    chain_states = dict()
    last_t = dict()

    # draw asynchronous strike times, collapse into synchronous setting
    for i in range(n_workers):
        n_strikes = np.random.poisson(N)
        strike_times = np.random.exponential(size=n_strikes).cumsum()
        df_temp = pd.DataFrame({"t": strike_times, "worker": i})
        df = pd.concat([df, df_temp], ignore_index=True)
        chain_states[i] = [init]
        last_t[i] = 0
    # print(chain_states)
    # print(chain_states[1])
    df = df.sort_values("t").set_index("t")
    if discrete:
        df["update"] = 0
    else:
        df["update"] = 0.0
    df["update_idx"] = 0

    idx_max = len(init)
    for w_i, t in zip(df["worker"].astype(int), df.index):
        # print(t)
        curr_state = chain_states[w_i][-1].copy()
        # update based on last moves
        for _, row in df[(df.index > last_t[w_i]) & (df.index < t)].iterrows():
            # print(row)
            proposal = row["update"]
            idx = row["update_idx"]
            w_s = int(row["worker"])
            assert w_i != w_s
            x_s = chain_states[w_s][-1].copy()
            x_i = curr_state.copy()
            if x_i[idx] != proposal:
                x_iprime = curr_state.copy()
                x_iprime[idx] = proposal

                joint_num = joint_pdf(x_iprime)
                joint_denom = joint_pdf(x_i)
                if (joint_num == 0) & (joint_denom == 0):
                    joint_ratio = 1
                else:
                    joint_ratio = joint_num / (joint_denom + 0.001)
                if joint_ratio != 0:
                    # transition probabilities from x_s -> x_i / x_i'
                    transition_num = 1
                    transition_denom = 1
                    for i, (a, b) in enumerate(zip(x_i, x_s)):
                        if a != b:
                            transition_num *= transition_probs(x_i[i], i, x_s)
                    for i, (a, b) in enumerate(zip(x_iprime, x_s)):
                        if a != b:
                            transition_denom *= transition_probs(x_iprime[i], i, x_s)
                    transition_ratio = transition_num / (transition_denom + 0.001)

                    # metropolis acceptance step
                    # print(joint_ratio * transition_ratio)
                    alpha = np.min([1.0, joint_ratio * transition_ratio])
                    u = np.random.uniform()
                    if u < alpha:
                        curr_state = x_iprime.copy()

        idx = np.random.randint(0, idx_max)
        newval = gibbs_update(idx, curr_state, full_conditionals)
        curr_state[idx] = newval

        df.at[t, "update"] = newval
        df.at[t, "update_idx"] = idx
        last_t[w_i] = t
        chain_states[w_i].append(curr_state)

    for i in range(n_workers):
        chain_states[i] = np.array(chain_states[i])
    return chain_states


# note: this is paralellizable, but this implementation isn't necessarily parelellized
# 'simply' need to parellelize the inner loop


def chrom_gibbs(init: list, full_conditionals, colorings: list, N=1000):
    """Chromatic Gibbs sampler

    Args:
        init (list): List of initialization for each node in graphical model
        full_conditionals (func): _description_
        colorings (list): multi-level list referring to node colorings. example: if there are two node colors and four nodes, list should look lik `[[0,1],[2,3]]` if nodes at indices 0 and 1 of init are color 0 and nodes at indices 2 and 3 are color 1.
        N (int, optional): Number of "time units" of sampling. Defaults to 1000.

    Returns:
        np.array: array of samples generated
    """
    samples = [init]
    col_idx_max = len(colorings)
    for i in range(N):
        col_idx = np.random.randint(0, col_idx_max)
        nextstate = samples[-1].copy()
        for idx in colorings[col_idx]:  # this loop should be parallelized
            newval = gibbs_update(idx, samples[-1], full_conditionals)
            nextstate[idx] = newval
        samples.append(nextstate)
    return np.array(samples)


# note: this is paralellizable, but this implementation isn't necessarily parelellized
# 'simply' need to parellelize the inner loop


def local_glauber(init, q, gamma=0.3, N=1000):
    """Local Glauber sampler for graph coloring problems

    Args:
        init (list): Initialization for each node in graphical model
        q (int): Number of colors available for graph coloring
        gamma (float, optional): Probability of node activation at each round. Defaults to 0.3.
        N (int, optional): Number of rounds of sampling. Defaults to 1000.

    Returns:
        np.array: Array of samples generated
    """
    samples = [init]
    n = len(init)
    for _ in range(N):
        proposals = []
        for val in samples[-1]:
            if random.uniform(0, 1) < gamma:
                proposals.append(random.randint(0, q - 1))
            else:
                proposals.append(val)
        newstate = []
        for idx in range(len(proposals)):
            if (proposals[(idx - 1) % n] == proposals[idx]) or (
                proposals[(idx + 1) % n] == proposals[idx]
            ):
                newstate.append(samples[-1][idx])
            else:
                newstate.append(proposals[idx])
        samples.append(newstate)
    return np.array(samples)


def dist_metro(init: list, proposal_samp, transition_probs, joint_pdf, N: int = 1000):
    """ "Sequentialized" distributed metroplis sampler. Follows the same rules, but one worker does all the work because this is real hard for me to implement exactly.

    Args:
        init (list): list of initial states for each node in factor graph
        proposal_samp (func): Function to draw samples from proposal distributions for each sample site. Takes as inputs (index_of_site_to_update, n_samples)
        transition_probs (func): Function to evaluate one-step transition probabilities. Takes as inputs (update, index_of_update, previous_state)
        joint_pdf (func): Function to evaluate (un-normalized) joint PDF. Takes as inputs (state)
        N (int, optional): Number of "time units" to sample. Equivalent to number of samples in sequential samplers. Defaults to 1000.

    Returns:
        np.array: array of samples
    """

    # create dataframe, dict for necessary shared information
    df = pd.DataFrame(columns=["t", "node", "proposal"])
    samples = [init]

    # draw asynchronous strike times, collapse into synchronous setting
    for i in range(len(init)):
        n_strikes = np.random.poisson(N)
        strike_times = np.random.exponential(size=n_strikes).cumsum()
        proposals = proposal_samp(i, n_strikes)
        df_temp = pd.DataFrame({"t": strike_times, "node": i, "proposal": proposals})
        df = pd.concat([df, df_temp], ignore_index=True)
    # print(chain_states)
    # print(chain_states[1])
    df = df.sort_values("t").set_index("t")

    for t, row in df.iterrows():
        # print(row)
        proposal = row["proposal"]
        idx = row["node"]
        x_i = samples[-1].copy()

        if x_i[idx] == proposal:
            samples.append(x_i.copy())
        else:
            x_iprime = samples[-1].copy()
            x_iprime[idx] = proposal

            joint_num = joint_pdf(x_iprime)
            joint_denom = joint_pdf(x_i)
            if (joint_num == 0) & (joint_denom == 0):
                joint_ratio = 1
            else:
                joint_ratio = joint_num / (joint_denom + 0.001)
            if joint_ratio == 0:
                samples.append(x_i.copy())
            else:
                # transition probabilities from x_s -> x_i / x_i
                transition_num = transition_probs(proposal, idx, x_i)
                transition_denom = transition_probs(x_i[idx], idx, x_iprime)
                transition_ratio = transition_num / (transition_denom + 0.001)
                # metropolis acceptance step
                # print(joint_ratio * transition_ratio)
                alpha = np.min([1.0, joint_ratio * transition_ratio])
                u = np.random.uniform()
                if u < alpha:
                    samples.append(x_iprime.copy())
                else:
                    samples.append(x_i.copy())
    return np.array(samples)
